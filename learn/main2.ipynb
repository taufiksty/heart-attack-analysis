{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
       "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
       "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
       "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
       "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
       "\n",
       "     caa  thall  output  \n",
       "298    0      3       0  \n",
       "299    0      3       0  \n",
       "300    2      3       0  \n",
       "301    1      3       0  \n",
       "302    1      2       0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/heart.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp      trtbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg    thalachh        exng     oldpeak         slp         caa  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "            thall      output  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.get_dummies(\n",
    "    df, columns=[\"sex\", \"cp\", \"fbs\", \"restecg\", \"exng\", \"slp\", \"caa\", \"thall\"]\n",
    ")\n",
    "standardScaler = StandardScaler()\n",
    "columns_scale = [\"age\", \"trtbps\", \"chol\", \"thalachh\", \"oldpeak\"]\n",
    "df[columns_scale] = standardScaler.fit_transform(df[columns_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'trtbps',\n",
       " 'chol',\n",
       " 'thalachh',\n",
       " 'oldpeak',\n",
       " 'output',\n",
       " 'sex_0',\n",
       " 'sex_1',\n",
       " 'cp_0',\n",
       " 'cp_1',\n",
       " 'cp_2',\n",
       " 'cp_3',\n",
       " 'fbs_0',\n",
       " 'fbs_1',\n",
       " 'restecg_0',\n",
       " 'restecg_1',\n",
       " 'restecg_2',\n",
       " 'exng_0',\n",
       " 'exng_1',\n",
       " 'slp_0',\n",
       " 'slp_1',\n",
       " 'slp_2',\n",
       " 'caa_0',\n",
       " 'caa_1',\n",
       " 'caa_2',\n",
       " 'caa_3',\n",
       " 'caa_4',\n",
       " 'thall_0',\n",
       " 'thall_1',\n",
       " 'thall_2',\n",
       " 'thall_3']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns.tolist())\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"output\"]\n",
    "X = df.drop([\"output\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203, 30)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=30, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 15)                465       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                160       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 8)                 88        \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 722\n",
      "Trainable params: 722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 3s 107ms/step - loss: 0.7657 - accuracy: 0.5616 - val_loss: 0.7666 - val_accuracy: 0.5100\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.7515 - accuracy: 0.5616 - val_loss: 0.7471 - val_accuracy: 0.5100\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7298 - accuracy: 0.5813 - val_loss: 0.7301 - val_accuracy: 0.5400\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7138 - accuracy: 0.5172 - val_loss: 0.7163 - val_accuracy: 0.5500\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7063 - accuracy: 0.5567 - val_loss: 0.7049 - val_accuracy: 0.5800\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6849 - accuracy: 0.5665 - val_loss: 0.6935 - val_accuracy: 0.6000\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6773 - accuracy: 0.5665 - val_loss: 0.6843 - val_accuracy: 0.5900\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6659 - accuracy: 0.6010 - val_loss: 0.6745 - val_accuracy: 0.6200\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6638 - accuracy: 0.5862 - val_loss: 0.6650 - val_accuracy: 0.6400\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6482 - accuracy: 0.6207 - val_loss: 0.6566 - val_accuracy: 0.6400\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6256 - accuracy: 0.6404 - val_loss: 0.6499 - val_accuracy: 0.6400\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6390 - accuracy: 0.6256 - val_loss: 0.6430 - val_accuracy: 0.6400\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5989 - accuracy: 0.6749 - val_loss: 0.6353 - val_accuracy: 0.6400\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6184 - accuracy: 0.6798 - val_loss: 0.6271 - val_accuracy: 0.6400\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6091 - accuracy: 0.6847 - val_loss: 0.6199 - val_accuracy: 0.6400\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5944 - accuracy: 0.6749 - val_loss: 0.6135 - val_accuracy: 0.6400\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6038 - accuracy: 0.6946 - val_loss: 0.6068 - val_accuracy: 0.6600\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5806 - accuracy: 0.7241 - val_loss: 0.5990 - val_accuracy: 0.6500\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5796 - accuracy: 0.7094 - val_loss: 0.5920 - val_accuracy: 0.6500\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5744 - accuracy: 0.7094 - val_loss: 0.5852 - val_accuracy: 0.6700\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5552 - accuracy: 0.7340 - val_loss: 0.5787 - val_accuracy: 0.6700\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5647 - accuracy: 0.6897 - val_loss: 0.5724 - val_accuracy: 0.6800\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5622 - accuracy: 0.7044 - val_loss: 0.5669 - val_accuracy: 0.7000\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5513 - accuracy: 0.7537 - val_loss: 0.5598 - val_accuracy: 0.7100\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5406 - accuracy: 0.7438 - val_loss: 0.5543 - val_accuracy: 0.7400\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5305 - accuracy: 0.7389 - val_loss: 0.5482 - val_accuracy: 0.7400\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5399 - accuracy: 0.7389 - val_loss: 0.5425 - val_accuracy: 0.7600\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5018 - accuracy: 0.7685 - val_loss: 0.5367 - val_accuracy: 0.7700\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5398 - accuracy: 0.7389 - val_loss: 0.5314 - val_accuracy: 0.7700\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5097 - accuracy: 0.7685 - val_loss: 0.5263 - val_accuracy: 0.7600\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5162 - accuracy: 0.7931 - val_loss: 0.5215 - val_accuracy: 0.7700\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4887 - accuracy: 0.7931 - val_loss: 0.5171 - val_accuracy: 0.7700\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5141 - accuracy: 0.7537 - val_loss: 0.5132 - val_accuracy: 0.7700\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4947 - accuracy: 0.7833 - val_loss: 0.5096 - val_accuracy: 0.7700\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.4922 - accuracy: 0.7931 - val_loss: 0.5054 - val_accuracy: 0.7700\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.4870 - accuracy: 0.7980 - val_loss: 0.5016 - val_accuracy: 0.7800\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.4802 - accuracy: 0.8030 - val_loss: 0.4974 - val_accuracy: 0.7900\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.4626 - accuracy: 0.8177 - val_loss: 0.4933 - val_accuracy: 0.8000\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.4685 - accuracy: 0.7833 - val_loss: 0.4902 - val_accuracy: 0.8000\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4679 - accuracy: 0.7882 - val_loss: 0.4858 - val_accuracy: 0.8000\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4820 - val_accuracy: 0.8000\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.4360 - accuracy: 0.8177 - val_loss: 0.4791 - val_accuracy: 0.8100\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4526 - accuracy: 0.8079 - val_loss: 0.4756 - val_accuracy: 0.8200\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.4538 - accuracy: 0.8128 - val_loss: 0.4726 - val_accuracy: 0.8100\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.4519 - accuracy: 0.7980 - val_loss: 0.4689 - val_accuracy: 0.8100\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4523 - accuracy: 0.7980 - val_loss: 0.4659 - val_accuracy: 0.8100\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4554 - accuracy: 0.8079 - val_loss: 0.4631 - val_accuracy: 0.8200\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4345 - accuracy: 0.8276 - val_loss: 0.4600 - val_accuracy: 0.8200\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4304 - accuracy: 0.8128 - val_loss: 0.4576 - val_accuracy: 0.8200\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4479 - accuracy: 0.8079 - val_loss: 0.4555 - val_accuracy: 0.8200\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4157 - accuracy: 0.8128 - val_loss: 0.4533 - val_accuracy: 0.8200\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4235 - accuracy: 0.8227 - val_loss: 0.4507 - val_accuracy: 0.8200\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4284 - accuracy: 0.8325 - val_loss: 0.4488 - val_accuracy: 0.8200\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4125 - accuracy: 0.8374 - val_loss: 0.4465 - val_accuracy: 0.8200\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4118 - accuracy: 0.8227 - val_loss: 0.4445 - val_accuracy: 0.8200\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4016 - accuracy: 0.8227 - val_loss: 0.4428 - val_accuracy: 0.8200\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4004 - accuracy: 0.8374 - val_loss: 0.4407 - val_accuracy: 0.8200\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4266 - accuracy: 0.8079 - val_loss: 0.4400 - val_accuracy: 0.8200\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4064 - accuracy: 0.8374 - val_loss: 0.4384 - val_accuracy: 0.8200\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4226 - accuracy: 0.8374 - val_loss: 0.4369 - val_accuracy: 0.8200\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3995 - accuracy: 0.8473 - val_loss: 0.4353 - val_accuracy: 0.8200\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3970 - accuracy: 0.8522 - val_loss: 0.4334 - val_accuracy: 0.8200\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3831 - accuracy: 0.8424 - val_loss: 0.4329 - val_accuracy: 0.8200\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3692 - accuracy: 0.8571 - val_loss: 0.4312 - val_accuracy: 0.8200\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3817 - accuracy: 0.8374 - val_loss: 0.4291 - val_accuracy: 0.8200\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4207 - accuracy: 0.8473 - val_loss: 0.4284 - val_accuracy: 0.8200\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3878 - accuracy: 0.8424 - val_loss: 0.4271 - val_accuracy: 0.8200\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3811 - accuracy: 0.8571 - val_loss: 0.4255 - val_accuracy: 0.8200\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3947 - accuracy: 0.8374 - val_loss: 0.4252 - val_accuracy: 0.8200\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4037 - accuracy: 0.8276 - val_loss: 0.4242 - val_accuracy: 0.8200\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.3754 - accuracy: 0.8276 - val_loss: 0.4236 - val_accuracy: 0.8200\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3615 - accuracy: 0.8424 - val_loss: 0.4226 - val_accuracy: 0.8200\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.3867 - accuracy: 0.8473 - val_loss: 0.4230 - val_accuracy: 0.8200\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3645 - accuracy: 0.8374 - val_loss: 0.4231 - val_accuracy: 0.8100\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3978 - accuracy: 0.8424 - val_loss: 0.4215 - val_accuracy: 0.8200\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3905 - accuracy: 0.8424 - val_loss: 0.4196 - val_accuracy: 0.8200\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3881 - accuracy: 0.8424 - val_loss: 0.4199 - val_accuracy: 0.8200\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3547 - accuracy: 0.8621 - val_loss: 0.4200 - val_accuracy: 0.8000\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3607 - accuracy: 0.8276 - val_loss: 0.4182 - val_accuracy: 0.8100\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3808 - accuracy: 0.8522 - val_loss: 0.4167 - val_accuracy: 0.8100\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3754 - accuracy: 0.8424 - val_loss: 0.4178 - val_accuracy: 0.8000\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3656 - accuracy: 0.8571 - val_loss: 0.4155 - val_accuracy: 0.8100\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3713 - accuracy: 0.8473 - val_loss: 0.4148 - val_accuracy: 0.8100\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3448 - accuracy: 0.8621 - val_loss: 0.4150 - val_accuracy: 0.8100\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3539 - accuracy: 0.8571 - val_loss: 0.4147 - val_accuracy: 0.8100\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3736 - accuracy: 0.8473 - val_loss: 0.4132 - val_accuracy: 0.8100\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.3550 - accuracy: 0.8670 - val_loss: 0.4130 - val_accuracy: 0.8100\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3428 - accuracy: 0.8818 - val_loss: 0.4129 - val_accuracy: 0.8100\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.3585 - accuracy: 0.8571 - val_loss: 0.4129 - val_accuracy: 0.8100\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3753 - accuracy: 0.8522 - val_loss: 0.4121 - val_accuracy: 0.8100\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3576 - accuracy: 0.8768 - val_loss: 0.4112 - val_accuracy: 0.8100\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3408 - accuracy: 0.8670 - val_loss: 0.4094 - val_accuracy: 0.8100\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3511 - accuracy: 0.8719 - val_loss: 0.4079 - val_accuracy: 0.8100\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3502 - accuracy: 0.8473 - val_loss: 0.4080 - val_accuracy: 0.8100\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3404 - accuracy: 0.8374 - val_loss: 0.4072 - val_accuracy: 0.8100\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3284 - accuracy: 0.8768 - val_loss: 0.4066 - val_accuracy: 0.8100\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3647 - accuracy: 0.8522 - val_loss: 0.4068 - val_accuracy: 0.8100\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3200 - accuracy: 0.8621 - val_loss: 0.4055 - val_accuracy: 0.8100\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3644 - accuracy: 0.8374 - val_loss: 0.4056 - val_accuracy: 0.8100\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3315 - accuracy: 0.8522 - val_loss: 0.4055 - val_accuracy: 0.8100\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3586 - accuracy: 0.8719 - val_loss: 0.4057 - val_accuracy: 0.8100\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3601 - accuracy: 0.8571 - val_loss: 0.4052 - val_accuracy: 0.8100\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3423 - accuracy: 0.8522 - val_loss: 0.4053 - val_accuracy: 0.8100\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3626 - accuracy: 0.8325 - val_loss: 0.4050 - val_accuracy: 0.8100\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3301 - accuracy: 0.8670 - val_loss: 0.4045 - val_accuracy: 0.8100\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3041 - accuracy: 0.8768 - val_loss: 0.4050 - val_accuracy: 0.8200\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3209 - accuracy: 0.8867 - val_loss: 0.4057 - val_accuracy: 0.8100\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3293 - accuracy: 0.8867 - val_loss: 0.4057 - val_accuracy: 0.8100\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.3363 - accuracy: 0.8621 - val_loss: 0.4043 - val_accuracy: 0.8200\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3312 - accuracy: 0.8571 - val_loss: 0.4040 - val_accuracy: 0.8100\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3384 - accuracy: 0.8571 - val_loss: 0.4036 - val_accuracy: 0.8100\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3336 - accuracy: 0.8473 - val_loss: 0.4038 - val_accuracy: 0.8100\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3125 - accuracy: 0.8818 - val_loss: 0.4037 - val_accuracy: 0.8100\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3459 - accuracy: 0.8621 - val_loss: 0.4044 - val_accuracy: 0.8100\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3157 - accuracy: 0.8818 - val_loss: 0.4047 - val_accuracy: 0.8000\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3417 - accuracy: 0.8473 - val_loss: 0.4040 - val_accuracy: 0.8100\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3093 - accuracy: 0.8621 - val_loss: 0.4039 - val_accuracy: 0.8100\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3323 - accuracy: 0.8670 - val_loss: 0.4035 - val_accuracy: 0.8100\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3399 - accuracy: 0.8522 - val_loss: 0.4034 - val_accuracy: 0.8100\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3153 - accuracy: 0.8473 - val_loss: 0.4017 - val_accuracy: 0.8100\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3235 - accuracy: 0.8768 - val_loss: 0.4012 - val_accuracy: 0.8100\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3403 - accuracy: 0.8670 - val_loss: 0.4009 - val_accuracy: 0.8100\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3183 - accuracy: 0.8670 - val_loss: 0.4017 - val_accuracy: 0.8100\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3125 - accuracy: 0.8571 - val_loss: 0.4015 - val_accuracy: 0.8100\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3363 - accuracy: 0.8768 - val_loss: 0.4030 - val_accuracy: 0.8200\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3222 - accuracy: 0.8621 - val_loss: 0.4021 - val_accuracy: 0.8100\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3380 - accuracy: 0.8670 - val_loss: 0.4020 - val_accuracy: 0.8200\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3223 - accuracy: 0.8621 - val_loss: 0.4005 - val_accuracy: 0.8100\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3086 - accuracy: 0.8867 - val_loss: 0.3998 - val_accuracy: 0.8100\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.3132 - accuracy: 0.8719 - val_loss: 0.4001 - val_accuracy: 0.8100\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3007 - accuracy: 0.8621 - val_loss: 0.3998 - val_accuracy: 0.8200\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3149 - accuracy: 0.8670 - val_loss: 0.3995 - val_accuracy: 0.8200\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3002 - accuracy: 0.8768 - val_loss: 0.4007 - val_accuracy: 0.8200\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3136 - accuracy: 0.8522 - val_loss: 0.4003 - val_accuracy: 0.8200\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2926 - accuracy: 0.8768 - val_loss: 0.4011 - val_accuracy: 0.8200\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3162 - accuracy: 0.8670 - val_loss: 0.4015 - val_accuracy: 0.8200\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3172 - accuracy: 0.8916 - val_loss: 0.4019 - val_accuracy: 0.8200\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2933 - accuracy: 0.8522 - val_loss: 0.4027 - val_accuracy: 0.8200\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2901 - accuracy: 0.8916 - val_loss: 0.4025 - val_accuracy: 0.8200\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.3157 - accuracy: 0.8768 - val_loss: 0.4015 - val_accuracy: 0.8100\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3143 - accuracy: 0.8867 - val_loss: 0.4016 - val_accuracy: 0.8200\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3173 - accuracy: 0.8670 - val_loss: 0.4019 - val_accuracy: 0.8100\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2912 - accuracy: 0.8768 - val_loss: 0.4021 - val_accuracy: 0.8200\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3105 - accuracy: 0.8818 - val_loss: 0.4027 - val_accuracy: 0.8200\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3195 - accuracy: 0.8424 - val_loss: 0.4023 - val_accuracy: 0.8200\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3174 - accuracy: 0.8768 - val_loss: 0.4023 - val_accuracy: 0.8200\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3168 - accuracy: 0.8670 - val_loss: 0.4031 - val_accuracy: 0.8200\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3167 - accuracy: 0.8768 - val_loss: 0.4027 - val_accuracy: 0.8200\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3113 - accuracy: 0.8966 - val_loss: 0.4026 - val_accuracy: 0.8200\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3079 - accuracy: 0.8818 - val_loss: 0.4031 - val_accuracy: 0.8200\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3007 - accuracy: 0.8621 - val_loss: 0.4030 - val_accuracy: 0.8200\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2970 - accuracy: 0.9064 - val_loss: 0.4034 - val_accuracy: 0.8200\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3218 - accuracy: 0.8768 - val_loss: 0.4037 - val_accuracy: 0.8200\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3289 - accuracy: 0.8621 - val_loss: 0.4030 - val_accuracy: 0.8100\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2955 - accuracy: 0.8916 - val_loss: 0.4035 - val_accuracy: 0.8200\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2852 - accuracy: 0.8867 - val_loss: 0.4047 - val_accuracy: 0.8200\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2955 - accuracy: 0.9015 - val_loss: 0.4048 - val_accuracy: 0.8200\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3139 - accuracy: 0.8768 - val_loss: 0.4029 - val_accuracy: 0.8100\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3055 - accuracy: 0.9015 - val_loss: 0.4028 - val_accuracy: 0.8100\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3105 - accuracy: 0.8966 - val_loss: 0.4027 - val_accuracy: 0.8200\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2829 - accuracy: 0.9064 - val_loss: 0.4018 - val_accuracy: 0.8100\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2902 - accuracy: 0.9015 - val_loss: 0.4027 - val_accuracy: 0.8200\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3133 - accuracy: 0.9163 - val_loss: 0.4012 - val_accuracy: 0.8200\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.2678 - accuracy: 0.9064 - val_loss: 0.4007 - val_accuracy: 0.8200\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2778 - accuracy: 0.9015 - val_loss: 0.4013 - val_accuracy: 0.8200\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2858 - accuracy: 0.8719 - val_loss: 0.4020 - val_accuracy: 0.8200\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2913 - accuracy: 0.8966 - val_loss: 0.4016 - val_accuracy: 0.8200\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.2936 - accuracy: 0.9015 - val_loss: 0.4023 - val_accuracy: 0.8200\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2808 - accuracy: 0.8867 - val_loss: 0.4025 - val_accuracy: 0.8200\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2972 - accuracy: 0.8818 - val_loss: 0.4019 - val_accuracy: 0.8200\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2832 - accuracy: 0.8818 - val_loss: 0.4020 - val_accuracy: 0.8200\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 0.2827 - accuracy: 0.8768 - val_loss: 0.4020 - val_accuracy: 0.8200\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3173 - accuracy: 0.8719 - val_loss: 0.4037 - val_accuracy: 0.8200\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2889 - accuracy: 0.8966 - val_loss: 0.4031 - val_accuracy: 0.8200\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2827 - accuracy: 0.8966 - val_loss: 0.4035 - val_accuracy: 0.8200\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2708 - accuracy: 0.9113 - val_loss: 0.4035 - val_accuracy: 0.8200\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2834 - accuracy: 0.8867 - val_loss: 0.4038 - val_accuracy: 0.8200\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2970 - accuracy: 0.8867 - val_loss: 0.4036 - val_accuracy: 0.8200\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.2600 - accuracy: 0.9015 - val_loss: 0.4041 - val_accuracy: 0.8200\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2736 - accuracy: 0.9113 - val_loss: 0.4041 - val_accuracy: 0.8200\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2880 - accuracy: 0.9163 - val_loss: 0.4044 - val_accuracy: 0.8200\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2858 - accuracy: 0.8916 - val_loss: 0.4045 - val_accuracy: 0.8200\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2896 - accuracy: 0.8867 - val_loss: 0.4049 - val_accuracy: 0.8200\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2911 - accuracy: 0.8867 - val_loss: 0.4044 - val_accuracy: 0.8200\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2840 - accuracy: 0.8966 - val_loss: 0.4046 - val_accuracy: 0.8200\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2860 - accuracy: 0.9064 - val_loss: 0.4054 - val_accuracy: 0.8200\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2928 - accuracy: 0.8966 - val_loss: 0.4047 - val_accuracy: 0.8200\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.2883 - accuracy: 0.8719 - val_loss: 0.4043 - val_accuracy: 0.8200\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2641 - accuracy: 0.8818 - val_loss: 0.4047 - val_accuracy: 0.8200\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.2508 - accuracy: 0.9113 - val_loss: 0.4048 - val_accuracy: 0.8200\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2777 - accuracy: 0.9064 - val_loss: 0.4049 - val_accuracy: 0.8200\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2949 - accuracy: 0.9015 - val_loss: 0.4052 - val_accuracy: 0.8200\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2734 - accuracy: 0.8867 - val_loss: 0.4053 - val_accuracy: 0.8200\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2707 - accuracy: 0.9163 - val_loss: 0.4053 - val_accuracy: 0.8200\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2819 - accuracy: 0.8966 - val_loss: 0.4044 - val_accuracy: 0.8200\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2717 - accuracy: 0.8916 - val_loss: 0.4048 - val_accuracy: 0.8200\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2574 - accuracy: 0.8966 - val_loss: 0.4045 - val_accuracy: 0.8200\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2527 - accuracy: 0.9113 - val_loss: 0.4053 - val_accuracy: 0.8200\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2669 - accuracy: 0.8966 - val_loss: 0.4044 - val_accuracy: 0.8200\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2723 - accuracy: 0.9064 - val_loss: 0.4046 - val_accuracy: 0.8200\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(\n",
    "    X_train.astype('float32'), y_train.astype('float32'), \n",
    "    epochs=200, \n",
    "    validation_data=(X_test.astype('float32'), y_test.astype('float32')),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08640619"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test.astype(np.float64))\n",
    "y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/model2.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel/model2.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(model, f)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/model2.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"model/model2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
